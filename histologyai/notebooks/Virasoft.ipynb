{"cells":[{"cell_type":"markdown","metadata":{"id":"FH0lHHYqd1pc"},"source":["\n","## Import Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":6874,"status":"ok","timestamp":1693247331728,"user":{"displayName":"f","userId":"09808555062517826231"},"user_tz":-180},"id":"UCHSFb0-ZRtA"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Furka\\anaconda3\\envs\\seg\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import DataLoader, random_split\n","import torchvision.models as models\n","from sklearn.model_selection import train_test_split\n","import wandb\n","import coloredlogs\n","import logging"]},{"cell_type":"markdown","metadata":{"id":"TT21mSeIfUgS"},"source":["## Identify running device,chose GPU if available"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"rN90_89xfTXZ"},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"markdown","metadata":{"id":"6AlzNdpMdz3M"},"source":["## Data Preprocessing"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"uBL3iShXZw5u"},"outputs":[],"source":["# Define data transformations including augmentation\n","train_transform = transforms.Compose([\n","    transforms.RandomResizedCrop(224),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n","    transforms.RandomRotation(10),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","val_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])"]},{"cell_type":"markdown","metadata":{},"source":["### Train/Test/Val Split"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Load entire dataset using ImageFolder\n","full_dataset = ImageFolder(root='Histology_Dataset/Train')\n","\n","# Split dataset into train, validation, and test sets\n","train_size = int(0.8 * len(full_dataset))\n","val_size = int(0.1 * len(full_dataset))\n","test_size = len(full_dataset) - train_size - val_size\n","\n","train_dataset, temp_dataset = random_split(full_dataset, [train_size, len(full_dataset) - train_size])\n","val_dataset, test_dataset = random_split(temp_dataset, [val_size, test_size])\n","\n","# Apply transformations to datasets\n","train_dataset.dataset.transform = train_transform\n","val_dataset.dataset.transform = val_transform\n","test_dataset.dataset.transform = val_transform\n","\n","# Create data loaders for train, validation, and test datasets\n","batch_size = 32\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size)\n"]},{"cell_type":"markdown","metadata":{"id":"PH9En8kpd4OD"},"source":["## Model Definition"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["torch.manual_seed(42)\n","def weights_init(m):\n","    if isinstance(m, nn.Conv2d):\n","        torch.nn.init.xavier_uniform(m.weight.data)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"_OhjuUPHd-CB"},"outputs":[],"source":["class HistologyClassifier(nn.Module):\n","    def __init__(self, num_classes):\n","        super(HistologyClassifier, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","        )\n","        self.classifier = nn.Sequential(\n","            nn.Dropout(0.5),\n","            nn.Linear(256 * 28 * 28, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.classifier(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"yViI4ZexeudK"},"source":["## Pre-Trained Model (Resnet)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"JHDiiLg0eruq"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Furka\\anaconda3\\envs\\seg\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  warnings.warn(\n","c:\\Users\\Furka\\anaconda3\\envs\\seg\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}],"source":["# Load pre-trained ResNet model\n","resnet = models.resnet18(pretrained=True)\n","num_features = resnet.fc.in_features\n","\n","# Modify the classifier of ResNet\n","resnet.fc = nn.Sequential(\n","    nn.Linear(num_features, 512),\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(512, 4)  # Assuming 4 classes\n",")\n","\n","# Add Batch Normalization\n","model_resnet = nn.Sequential(\n","    resnet,\n","    nn.BatchNorm1d(4)  # Applying BatchNorm to the output of the classifier\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"nvcJXzrTeOoj"},"source":["## Define Train/Test Functions\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Configure the logger\n","coloredlogs.install(level=logging.INFO)\n","logger = logging.getLogger(__name__)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def train_model(model, train_loader, valid_loader, device, project_name, exp_name, num_epochs=10):\n","    model.to(device)\n","    criterion = nn.CrossEntropyLoss()\n","    lr = 0.001\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    # Track metrics\n","    training_metrics = {}\n","    wandb.init(project=project_name,name=exp_name,\n","        config={\n","            \"lr\":lr,\n","            'optimizer':'adam',\n","            \"num_epoch\":num_epochs})\n","    # Training\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","        running_corrects = 0\n","        size_train_loader = len(train_loader)\n","        for inputs, labels in train_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            # Calculate Train Accuracy\n","            _, preds = torch.max(outputs, 1)\n","            running_loss += loss.item() * inputs.size(0)\n","            running_corrects += torch.sum(preds == labels.data)\n","        train_loss = running_loss/size_train_loader\n","        train_acc = running_corrects.double() / size_train_loader\n","        # Validation\n","        model.eval()\n","        with torch.no_grad():\n","            valid_loss = 0.0\n","            running_corrects = 0\n","            # total = 0\n","            size_val_loader = len(val_loader)\n","            for inputs, labels in valid_loader:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","                outputs = model(inputs)\n","                loss = criterion(outputs, labels)\n","                valid_loss += loss.item() * inputs.size(0)\n","                _, preds = outputs.max(1)\n","                running_corrects += torch.sum(preds == labels.data)\n","            val_loss = valid_loss / size_val_loader\n","            val_acc = running_corrects.double() / size_val_loader\n","        metrics = {\n","                    \"train_loss\": train_loss,\n","                    \"train_acc\": train_acc,\n","                    \"val_loss\": val_loss,\n","                    \"val_acc\": val_acc,\n","                    \"epoch\":epoch}\n","        wandb.log({\n","                \"train_loss\": metrics['train_loss'],\n","                \"train_acc\": metrics['train_acc'].item(),\n","                \"val_loss\": metrics['val_loss'],\n","                \"val_acc\": metrics['val_acc'].item(),\n","            })\n","        logger.info(\n","                    f\"Epoch [{epoch+1}/{num_epochs}] - \"\n","                    f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n","                    f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\"\n","                )\n","    return {\n","        \"model\": model,\n","        \"training_metrics\":training_metrics\n","    }\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Furka\\AppData\\Local\\Temp\\ipykernel_1464\\1361703646.py:4: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n","  torch.nn.init.xavier_uniform(m.weight.data)\n","\u001b[32m2023-09-01 12:44:38\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34mwandb.jupyter[1464]\u001b[0m \u001b[1;30mERROR\u001b[0m \u001b[31mFailed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfurkanayik\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.9"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>f:\\Furkan\\Coding\\AI\\Virasoft_Assignment\\wandb\\run-20230901_124440-1en1n55v</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/furkanayik/HistologyClassifier/runs/1en1n55v' target=\"_blank\">custom_model</a></strong> to <a href='https://wandb.ai/furkanayik/HistologyClassifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/furkanayik/HistologyClassifier' target=\"_blank\">https://wandb.ai/furkanayik/HistologyClassifier</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/furkanayik/HistologyClassifier/runs/1en1n55v' target=\"_blank\">https://wandb.ai/furkanayik/HistologyClassifier/runs/1en1n55v</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[32m2023-09-01 12:45:36\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [1/50] - Train Loss: 157.0298, Train Acc: 8.2500, Val Loss: 44.6952, Val Acc: 6.0000\n","\u001b[32m2023-09-01 12:45:45\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [2/50] - Train Loss: 44.5655, Train Acc: 7.1250, Val Loss: 44.2925, Val Acc: 8.0000\n","\u001b[32m2023-09-01 12:45:53\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [3/50] - Train Loss: 44.4521, Train Acc: 7.2500, Val Loss: 44.3904, Val Acc: 3.0000\n","\u001b[32m2023-09-01 12:46:02\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [4/50] - Train Loss: 44.4205, Train Acc: 6.5000, Val Loss: 44.3618, Val Acc: 6.0000\n","\u001b[32m2023-09-01 12:46:10\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [5/50] - Train Loss: 44.6604, Train Acc: 9.0000, Val Loss: 44.4825, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:46:19\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [6/50] - Train Loss: 44.3606, Train Acc: 8.8750, Val Loss: 44.5188, Val Acc: 6.0000\n","\u001b[32m2023-09-01 12:46:28\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [7/50] - Train Loss: 44.3630, Train Acc: 8.1250, Val Loss: 44.3263, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:46:36\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [8/50] - Train Loss: 44.3269, Train Acc: 8.3750, Val Loss: 44.4964, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:46:45\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [9/50] - Train Loss: 44.3229, Train Acc: 9.0000, Val Loss: 43.8250, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:46:53\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [10/50] - Train Loss: 44.0034, Train Acc: 8.8750, Val Loss: 43.7064, Val Acc: 8.0000\n","\u001b[32m2023-09-01 12:47:02\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [11/50] - Train Loss: 44.3165, Train Acc: 9.5000, Val Loss: 44.4575, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:47:10\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [12/50] - Train Loss: 44.4112, Train Acc: 7.7500, Val Loss: 44.3575, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:47:19\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [13/50] - Train Loss: 44.4149, Train Acc: 7.5000, Val Loss: 44.3631, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:47:28\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [14/50] - Train Loss: 44.3986, Train Acc: 7.5000, Val Loss: 44.3778, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:47:36\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [15/50] - Train Loss: 44.3913, Train Acc: 7.5000, Val Loss: 44.3992, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:47:45\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [16/50] - Train Loss: 44.3776, Train Acc: 7.5000, Val Loss: 44.4000, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:47:53\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [17/50] - Train Loss: 44.3709, Train Acc: 7.8750, Val Loss: 44.4149, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:48:02\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [18/50] - Train Loss: 44.3535, Train Acc: 8.3750, Val Loss: 44.4157, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:48:11\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [19/50] - Train Loss: 44.3417, Train Acc: 8.5000, Val Loss: 44.4183, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:48:19\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [20/50] - Train Loss: 44.3431, Train Acc: 8.7500, Val Loss: 44.4423, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:48:28\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [21/50] - Train Loss: 44.3084, Train Acc: 9.0000, Val Loss: 44.4778, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:48:37\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [22/50] - Train Loss: 44.3038, Train Acc: 9.0000, Val Loss: 44.4912, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:48:45\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [23/50] - Train Loss: 44.3229, Train Acc: 9.0000, Val Loss: 44.4916, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:48:54\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [24/50] - Train Loss: 44.3165, Train Acc: 9.0000, Val Loss: 44.4997, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:49:03\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [25/50] - Train Loss: 44.2621, Train Acc: 9.0000, Val Loss: 44.4985, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:49:11\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [26/50] - Train Loss: 44.2805, Train Acc: 9.0000, Val Loss: 44.5329, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:49:21\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [27/50] - Train Loss: 44.3253, Train Acc: 9.0000, Val Loss: 44.5084, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:49:30\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [28/50] - Train Loss: 44.3075, Train Acc: 9.0000, Val Loss: 44.5520, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:49:38\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [29/50] - Train Loss: 44.2234, Train Acc: 9.0000, Val Loss: 44.4514, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:49:47\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [30/50] - Train Loss: 44.2251, Train Acc: 9.0000, Val Loss: 44.4728, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:49:55\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [31/50] - Train Loss: 43.5440, Train Acc: 9.0000, Val Loss: 44.8712, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:50:04\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [32/50] - Train Loss: 44.3192, Train Acc: 9.0000, Val Loss: 44.5139, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:50:13\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [33/50] - Train Loss: 44.2871, Train Acc: 9.0000, Val Loss: 44.5273, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:50:21\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [34/50] - Train Loss: 44.2968, Train Acc: 9.0000, Val Loss: 44.5288, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:50:30\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [35/50] - Train Loss: 44.2773, Train Acc: 9.0000, Val Loss: 44.5438, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:50:38\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [36/50] - Train Loss: 44.2972, Train Acc: 9.0000, Val Loss: 44.5557, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:50:47\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [37/50] - Train Loss: 44.3021, Train Acc: 9.0000, Val Loss: 44.5636, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:50:55\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [38/50] - Train Loss: 44.2614, Train Acc: 9.0000, Val Loss: 44.5722, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:51:04\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [39/50] - Train Loss: 44.3149, Train Acc: 9.0000, Val Loss: 44.5903, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:51:12\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [40/50] - Train Loss: 44.2975, Train Acc: 9.0000, Val Loss: 44.5935, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:51:21\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [41/50] - Train Loss: 44.2796, Train Acc: 9.0000, Val Loss: 44.6007, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:51:30\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [42/50] - Train Loss: 44.2829, Train Acc: 9.0000, Val Loss: 44.6025, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:51:38\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [43/50] - Train Loss: 44.3155, Train Acc: 9.0000, Val Loss: 44.6090, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:51:47\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [44/50] - Train Loss: 44.2687, Train Acc: 9.0000, Val Loss: 44.6087, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:51:56\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [45/50] - Train Loss: 44.2898, Train Acc: 9.0000, Val Loss: 44.6081, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:52:04\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [46/50] - Train Loss: 44.2341, Train Acc: 9.0000, Val Loss: 44.6144, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:52:13\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [47/50] - Train Loss: 44.2820, Train Acc: 9.0000, Val Loss: 44.6286, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:52:21\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [48/50] - Train Loss: 44.2868, Train Acc: 9.0000, Val Loss: 44.6208, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:52:30\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [49/50] - Train Loss: 44.2677, Train Acc: 9.0000, Val Loss: 44.6316, Val Acc: 7.0000\n","\u001b[32m2023-09-01 12:52:38\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[1464]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [50/50] - Train Loss: 44.2529, Train Acc: 9.0000, Val Loss: 44.6348, Val Acc: 7.0000\n"]},{"data":{"text/plain":["{'model': HistologyClassifier(\n","   (features): Sequential(\n","     (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","     (1): ReLU()\n","     (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","     (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","     (4): ReLU()\n","     (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","     (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","     (7): ReLU()\n","     (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","   )\n","   (classifier): Sequential(\n","     (0): Dropout(p=0.5, inplace=False)\n","     (1): Linear(in_features=200704, out_features=512, bias=True)\n","     (2): ReLU()\n","     (3): Dropout(p=0.5, inplace=False)\n","     (4): Linear(in_features=512, out_features=4, bias=True)\n","   )\n"," ),\n"," 'training_metrics': {}}"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["model_histology_custom = HistologyClassifier(num_classes=4)\n","model_histology_custom.apply(weights_init)\n","train_result = train_model(model_histology_custom, train_loader, val_loader, device, project_name=\"HistologyClassifier\", exp_name=\"custom_model\",num_epochs=50)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"T9ipzsSyeQvR"},"outputs":[],"source":["def test_model(model):\n","    model.eval()\n","    with torch.no_grad():\n","        test_loss = 0.0\n","        correct = 0\n","        total = 0\n","        for inputs, labels in test_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            test_loss += loss.item()\n","\n","            _, predicted = outputs.max(1)\n","            total += labels.size(0)\n","            correct += predicted.eq(labels).sum().item()\n","        avg_test_loss = test_loss/len(test_loader)\n","        acc_test = correct/total\n","        print(f\"Test Loss: {avg_test_loss:.4f}, \"\n","            f\"Test Accuracy: {100*acc_test:.2f}%\")\n","        return avg_test_loss, acc_test\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/html":["Finishing last run (ID:zmdzm3lk) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">resnet_train</strong> at: <a href='https://wandb.ai/furkanayik/Histology_Classification/runs/zmdzm3lk' target=\"_blank\">https://wandb.ai/furkanayik/Histology_Classification/runs/zmdzm3lk</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>.\\wandb\\run-20230901_042342-zmdzm3lk\\logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:zmdzm3lk). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.15.9"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>f:\\Furkan\\Coding\\AI\\Virasoft_Assignment\\wandb\\run-20230901_042425-uyke8gf7</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/furkanayik/Histology_Classification/runs/uyke8gf7' target=\"_blank\">resnet_train</a></strong> to <a href='https://wandb.ai/furkanayik/Histology_Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/furkanayik/Histology_Classification' target=\"_blank\">https://wandb.ai/furkanayik/Histology_Classification</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/furkanayik/Histology_Classification/runs/uyke8gf7' target=\"_blank\">https://wandb.ai/furkanayik/Histology_Classification/runs/uyke8gf7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[32m2023-09-01 04:24:47\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [1/50] - Train Loss: 42.5706, Train Acc: 12.8750, Val Loss: 69.1040, Val Acc: 1000.0000\n","\u001b[32m2023-09-01 04:24:57\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [2/50] - Train Loss: 35.5436, Train Acc: 17.2500, Val Loss: 82.5637, Val Acc: 900.0000\n","\u001b[32m2023-09-01 04:25:06\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [3/50] - Train Loss: 33.8744, Train Acc: 18.8750, Val Loss: 104.1375, Val Acc: 1000.0000\n","\u001b[32m2023-09-01 04:25:14\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [4/50] - Train Loss: 29.7875, Train Acc: 22.2500, Val Loss: 137.4967, Val Acc: 700.0000\n","\u001b[32m2023-09-01 04:25:22\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [5/50] - Train Loss: 28.8408, Train Acc: 21.3750, Val Loss: 38.0188, Val Acc: 1500.0000\n","\u001b[32m2023-09-01 04:25:31\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [6/50] - Train Loss: 29.5655, Train Acc: 20.3750, Val Loss: 47.4698, Val Acc: 1200.0000\n","\u001b[32m2023-09-01 04:25:39\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [7/50] - Train Loss: 25.2378, Train Acc: 22.5000, Val Loss: 36.3628, Val Acc: 1300.0000\n","\u001b[32m2023-09-01 04:25:47\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [8/50] - Train Loss: 25.5365, Train Acc: 22.7500, Val Loss: 32.9371, Val Acc: 1800.0000\n","\u001b[32m2023-09-01 04:25:56\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [9/50] - Train Loss: 23.2586, Train Acc: 23.6250, Val Loss: 38.1745, Val Acc: 1700.0000\n","\u001b[32m2023-09-01 04:26:04\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [10/50] - Train Loss: 20.2619, Train Acc: 25.3750, Val Loss: 39.5966, Val Acc: 1800.0000\n","\u001b[32m2023-09-01 04:26:12\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [11/50] - Train Loss: 22.8566, Train Acc: 24.0000, Val Loss: 29.3487, Val Acc: 2100.0000\n","\u001b[32m2023-09-01 04:26:20\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [12/50] - Train Loss: 19.0546, Train Acc: 26.1250, Val Loss: 41.6390, Val Acc: 1600.0000\n","\u001b[32m2023-09-01 04:26:29\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [13/50] - Train Loss: 18.9239, Train Acc: 26.0000, Val Loss: 39.1221, Val Acc: 1600.0000\n","\u001b[32m2023-09-01 04:26:37\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [14/50] - Train Loss: 20.9489, Train Acc: 24.6250, Val Loss: 42.2835, Val Acc: 1500.0000\n","\u001b[32m2023-09-01 04:26:45\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [15/50] - Train Loss: 21.5087, Train Acc: 24.0000, Val Loss: 46.7411, Val Acc: 1500.0000\n","\u001b[32m2023-09-01 04:26:53\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [16/50] - Train Loss: 20.1515, Train Acc: 25.5000, Val Loss: 38.9428, Val Acc: 1700.0000\n","\u001b[32m2023-09-01 04:27:01\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [17/50] - Train Loss: 16.9916, Train Acc: 28.1250, Val Loss: 31.3278, Val Acc: 1800.0000\n","\u001b[32m2023-09-01 04:27:10\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [18/50] - Train Loss: 18.8385, Train Acc: 26.6250, Val Loss: 40.9508, Val Acc: 1700.0000\n","\u001b[32m2023-09-01 04:27:18\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [19/50] - Train Loss: 16.8864, Train Acc: 27.1250, Val Loss: 33.1564, Val Acc: 1900.0000\n","\u001b[32m2023-09-01 04:27:27\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [20/50] - Train Loss: 17.2163, Train Acc: 26.8750, Val Loss: 38.9850, Val Acc: 1600.0000\n","\u001b[32m2023-09-01 04:27:35\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [21/50] - Train Loss: 17.9180, Train Acc: 26.1250, Val Loss: 30.9774, Val Acc: 1800.0000\n","\u001b[32m2023-09-01 04:27:44\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [22/50] - Train Loss: 15.8693, Train Acc: 27.6250, Val Loss: 24.7252, Val Acc: 2300.0000\n","\u001b[32m2023-09-01 04:27:52\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [23/50] - Train Loss: 18.1943, Train Acc: 26.6250, Val Loss: 40.2720, Val Acc: 1600.0000\n","\u001b[32m2023-09-01 04:28:00\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [24/50] - Train Loss: 16.0060, Train Acc: 27.7500, Val Loss: 38.9460, Val Acc: 1700.0000\n","\u001b[32m2023-09-01 04:28:09\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [25/50] - Train Loss: 17.0375, Train Acc: 26.8750, Val Loss: 33.5183, Val Acc: 1800.0000\n","\u001b[32m2023-09-01 04:28:17\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [26/50] - Train Loss: 20.7437, Train Acc: 24.8750, Val Loss: 32.9531, Val Acc: 1800.0000\n","\u001b[32m2023-09-01 04:28:26\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [27/50] - Train Loss: 15.6051, Train Acc: 27.0000, Val Loss: 41.0229, Val Acc: 1500.0000\n","\u001b[32m2023-09-01 04:28:34\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [28/50] - Train Loss: 16.3871, Train Acc: 26.7500, Val Loss: 38.6868, Val Acc: 1700.0000\n","\u001b[32m2023-09-01 04:28:42\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [29/50] - Train Loss: 13.9743, Train Acc: 28.8750, Val Loss: 18.1750, Val Acc: 2700.0000\n","\u001b[32m2023-09-01 04:28:51\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [30/50] - Train Loss: 13.8212, Train Acc: 28.5000, Val Loss: 24.5990, Val Acc: 2100.0000\n","\u001b[32m2023-09-01 04:28:59\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [31/50] - Train Loss: 14.1736, Train Acc: 28.8750, Val Loss: 30.3483, Val Acc: 2000.0000\n","\u001b[32m2023-09-01 04:29:07\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [32/50] - Train Loss: 14.3427, Train Acc: 27.8750, Val Loss: 31.7598, Val Acc: 2100.0000\n","\u001b[32m2023-09-01 04:29:15\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [33/50] - Train Loss: 14.3131, Train Acc: 27.6250, Val Loss: 43.1427, Val Acc: 1400.0000\n","\u001b[32m2023-09-01 04:29:23\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [34/50] - Train Loss: 15.4448, Train Acc: 27.2500, Val Loss: 26.7817, Val Acc: 2300.0000\n","\u001b[32m2023-09-01 04:29:32\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [35/50] - Train Loss: 13.9901, Train Acc: 28.2500, Val Loss: 22.8465, Val Acc: 2500.0000\n","\u001b[32m2023-09-01 04:29:40\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [36/50] - Train Loss: 15.9752, Train Acc: 27.1250, Val Loss: 22.9076, Val Acc: 2400.0000\n","\u001b[32m2023-09-01 04:29:48\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [37/50] - Train Loss: 13.4292, Train Acc: 28.8750, Val Loss: 23.5852, Val Acc: 2400.0000\n","\u001b[32m2023-09-01 04:29:56\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [38/50] - Train Loss: 13.8433, Train Acc: 28.6250, Val Loss: 24.8265, Val Acc: 2500.0000\n","\u001b[32m2023-09-01 04:30:04\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [39/50] - Train Loss: 14.9790, Train Acc: 27.3750, Val Loss: 30.0952, Val Acc: 2100.0000\n","\u001b[32m2023-09-01 04:30:12\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [40/50] - Train Loss: 12.6066, Train Acc: 28.6250, Val Loss: 21.7523, Val Acc: 2300.0000\n","\u001b[32m2023-09-01 04:30:21\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [41/50] - Train Loss: 11.7384, Train Acc: 29.5000, Val Loss: 25.5017, Val Acc: 2200.0000\n","\u001b[32m2023-09-01 04:30:29\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [42/50] - Train Loss: 13.8714, Train Acc: 27.7500, Val Loss: 25.3741, Val Acc: 2400.0000\n","\u001b[32m2023-09-01 04:30:37\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [43/50] - Train Loss: 11.4011, Train Acc: 29.5000, Val Loss: 35.5285, Val Acc: 1700.0000\n","\u001b[32m2023-09-01 04:30:46\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [44/50] - Train Loss: 13.9158, Train Acc: 27.8750, Val Loss: 26.8009, Val Acc: 2400.0000\n","\u001b[32m2023-09-01 04:30:54\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [45/50] - Train Loss: 14.3243, Train Acc: 27.6250, Val Loss: 31.8878, Val Acc: 1800.0000\n","\u001b[32m2023-09-01 04:31:02\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [46/50] - Train Loss: 13.9003, Train Acc: 28.0000, Val Loss: 23.3209, Val Acc: 2300.0000\n","\u001b[32m2023-09-01 04:31:11\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [47/50] - Train Loss: 13.7922, Train Acc: 27.7500, Val Loss: 25.8868, Val Acc: 2300.0000\n","\u001b[32m2023-09-01 04:31:19\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [48/50] - Train Loss: 13.5143, Train Acc: 27.6250, Val Loss: 29.2489, Val Acc: 2200.0000\n","\u001b[32m2023-09-01 04:31:27\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [49/50] - Train Loss: 11.8551, Train Acc: 28.2500, Val Loss: 28.9684, Val Acc: 1900.0000\n","\u001b[32m2023-09-01 04:31:35\u001b[0m \u001b[35mAntonWindows\u001b[0m \u001b[34m__main__[26428]\u001b[0m \u001b[1;30mINFO\u001b[0m Epoch [50/50] - Train Loss: 12.7612, Train Acc: 28.2500, Val Loss: 44.2271, Val Acc: 1400.0000\n"]},{"data":{"text/plain":["{'model': Sequential(\n","   (0): ResNet(\n","     (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (relu): ReLU(inplace=True)\n","     (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","     (layer1): Sequential(\n","       (0): BasicBlock(\n","         (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","         (relu): ReLU(inplace=True)\n","         (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","         (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       )\n","       (1): BasicBlock(\n","         (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","         (relu): ReLU(inplace=True)\n","         (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","         (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       )\n","     )\n","     (layer2): Sequential(\n","       (0): BasicBlock(\n","         (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","         (relu): ReLU(inplace=True)\n","         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","         (downsample): Sequential(\n","           (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","           (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","         )\n","       )\n","       (1): BasicBlock(\n","         (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","         (relu): ReLU(inplace=True)\n","         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       )\n","     )\n","     (layer3): Sequential(\n","       (0): BasicBlock(\n","         (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","         (relu): ReLU(inplace=True)\n","         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","         (downsample): Sequential(\n","           (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","           (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","         )\n","       )\n","       (1): BasicBlock(\n","         (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","         (relu): ReLU(inplace=True)\n","         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       )\n","     )\n","     (layer4): Sequential(\n","       (0): BasicBlock(\n","         (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","         (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","         (relu): ReLU(inplace=True)\n","         (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","         (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","         (downsample): Sequential(\n","           (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","           (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","         )\n","       )\n","       (1): BasicBlock(\n","         (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","         (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","         (relu): ReLU(inplace=True)\n","         (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","         (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       )\n","     )\n","     (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","     (fc): Sequential(\n","       (0): Linear(in_features=512, out_features=512, bias=True)\n","       (1): ReLU()\n","       (2): Dropout(p=0.5, inplace=False)\n","       (3): Linear(in_features=512, out_features=4, bias=True)\n","     )\n","   )\n","   (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"," ),\n"," 'training_metrics': {}}"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["train_model(model_resnet, train_loader, val_loader, device, \n","    project_name=\"Histology_Classification\", \n","    exp_name=\"resnet_train\",\n","    num_epochs=50)"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Train Custom Model"]},{"cell_type":"markdown","metadata":{"id":"m6p0eTu4eVGF"},"source":["## What would you do to improve the performance of the classifier ?\n","\n","To improve the performance of the histology image classifier, you can consider several strategies. Keep in mind that experimentation and tuning are crucial in achieving better results. Here are some approaches you can take:\n","\n","1. **Data Augmentation:** Apply various data augmentation techniques to increase the diversity of your training dataset. Common augmentations include random rotations, flips, shifts, brightness adjustments, and zooms. This helps the model generalize better to different variations of the same image.\n","\n","2. **Transfer Learning:** Utilize pre-trained models like ResNet, VGG, or Inception, which are trained on large datasets like ImageNet. Fine-tune these models on your histology dataset. Transfer learning can significantly boost performance, as the models have already learned useful features from a diverse range of images.\n","\n","3. **Learning Rate Scheduling:** Adjust the learning rate during training. Start with a larger learning rate and then gradually reduce it as training progresses. This can help the model converge faster and prevent overshooting.\n","\n","4. **Model Architecture:** Experiment with different CNN architectures, layer depths, kernel sizes, and the number of filters. More complex architectures might capture finer features but could also lead to overfitting.\n","\n","5. **Regularization:** Implement regularization techniques like dropout and weight decay to prevent overfitting. These techniques help the model generalize better to unseen data.\n","\n","6. **Batch Normalization:** Add batch normalization layers to normalize the activations of each layer, which can speed up training and improve convergence.\n","\n","7. **Optimizer Choice:** Besides Adam, experiment with other optimizers like SGD with momentum or RMSprop. Different optimizers can have varying effects on convergence speed and generalization.\n","\n","8. **Hyperparameter Tuning:** Systematically search for optimal hyperparameters, such as learning rate, dropout rate, batch size, and others. Tools like random search or grid search can be used for this purpose.\n","\n","9. **Ensemble Methods:** Train multiple models with different initializations or architectures and combine their predictions to make final decisions. Ensemble methods can help reduce model variance and improve overall performance.\n","\n","10. **Class Imbalance Handling:** If your classes are imbalanced, apply techniques like class weighting or oversampling the minority classes to prevent the model from being biased towards the majority class.\n","\n","11. **Regular Monitoring:** Continuously monitor training and validation curves. If the validation loss starts increasing while training loss is decreasing, it might indicate overfitting. You might need to stop training or adjust regularization.\n","\n","12. **Model Interpretability:** Utilize techniques like Grad-CAM to understand which regions of the image are influencing the model's decisions. This can help identify whether the model is focusing on relevant regions.\n","\n","Remember, there's no one-size-fits-all solution, and the effectiveness of these strategies can vary based on your specific dataset and problem. It's recommended to experiment with a combination of these techniques to find the best approach for your histology image classifier."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8uuiG0zteZU4"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPTIoxNrtJHIKwnQc2ZjeCD","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"nbformat":4,"nbformat_minor":0}
